---
status: shipped
scope: feature/push-alerts/implementation
ai-priority: high
tags: [implementation, architecture]
relates-to: [product-spec.md, qa-plan.md]
last-verified: 2026-01-31
---

> **[MIGRATION NOTICE]**
> Canonical location for this tech spec. Migrated from `/docs/ai-first/tech-spec-push-alerts.md` on 2026-01-26.
> See also: [Product Spec](product-spec.md) and [Push Alerts Review](push-alerts-review.md).

# Tech Spec: Context Streaming / Push-Based Alerts (Phase 3)

## Status

**Consolidated spec.** This document merges two delivery mechanisms:
1. **Push-alerts (passive):** Alerts attached to `observe` responses — always enabled
2. **Context streaming (active):** Proactive MCP notifications — opt-in via `configure_streaming`

Dedicated HTTP event-stream endpoints are **deferred to v2**. MCP notifications are the primary active delivery mechanism.

---

## Purpose

Instead of requiring the AI to poll multiple tools to detect problems, the server proactively surfaces issues:

1. **Passive mode (default):** Every `observe` response includes an `_alerts` array with accumulated alerts since the last call
2. **Active mode (opt-in):** `configure_streaming` enables proactive MCP notifications pushed to stdout without requiring tool calls

## How It Works

### Alert Accumulation

The server maintains an alert buffer on `ToolHandler`. Alerts are generated by background checks and incoming webhooks. When any `observe` tool call is processed, accumulated alerts are attached to the response and the buffer is drained.

The alert buffer is a slice of `Alert` structs, capped at 50 entries. When full, oldest alerts are evicted (FIFO). Alerts are accumulated between `observe` calls — if the AI hasn't called `observe` in a while, it gets all pending alerts on the next call.

### Alert Structure

Each alert has:

- `severity`: one of `"info"`, `"warning"`, `"error"`
- `category`: one of `"regression"`, `"anomaly"`, `"ci"`, `"noise"`, `"threshold"`
- `title`: short human-readable summary (one line)
- `detail`: longer explanation with data points
- `timestamp`: ISO 8601 when the alert was generated
- `source`: what generated it (e.g., `"performance_monitor"`, `"ci_webhook"`, `"noise_detector"`)

### Alert Sources

**Performance regressions** (category: `"regression"`):
When a new performance snapshot arrives and the server detects a regression against the baseline (FCP/LCP/CLS/INP exceeding thresholds), an alert is generated. The threshold is 20% degradation from baseline for timing metrics, or 0.1 increase for CLS.

**Anomaly detection** (category: `"anomaly"`):
When error frequency spikes (more than 3x the rolling average in a 10-second window), an alert is generated. The rolling average is computed from the last 60 seconds of error entries.

**CI/CD results** (category: `"ci"`):
When the CI webhook receives a result, it generates an alert with the build status, test results summary, and any failure details.

**Noise rule triggers** (category: `"noise"`):
When auto-detection runs and finds new noise patterns, an informational alert is generated so the AI knows the signal-to-noise ratio improved.

**Threshold breaches** (category: `"threshold"`):
Memory pressure transitions (normal→soft, soft→hard) and circuit breaker state changes generate alerts.

### Response Format

The `observe` response gains an additional content block when alerts exist. The first content block remains the tool's normal output. A second content block with type `"text"` is appended containing the alerts as JSON:

```json
{
  "content": [
    {"type": "text", "text": "<normal observe output>"},
    {"type": "text", "text": "--- ALERTS (3) ---\n<alerts JSON array>"}
  ]
}
```

The alerts block is only appended when there are pending alerts. When no alerts exist, the response is identical to the current behavior (single content block).

### Situation Synthesis

Rather than dumping raw alerts, the server performs basic triage:

1. **Deduplication**: If the same regression is detected multiple times (e.g., repeated page loads all showing the same LCP regression), only one alert is generated with a count field.
2. **Priority ordering**: Alerts are sorted by severity (error > warning > info) then by timestamp (newest first).
3. **Correlation**: If a performance regression and an error spike occur within the same 5-second window, they're grouped into a single compound alert with both details.
4. **Summary prefix**: When more than 3 alerts exist, the alerts block starts with a one-line summary: "3 alerts: 1 regression, 1 anomaly, 1 CI failure"

### CI/CD Webhook Receiver

A new HTTP endpoint: `POST /ci-result`

Request body (JSON):
```json
{
  "status": "success" | "failure" | "error",
  "source": "github-actions" | "gitlab-ci" | "custom",
  "ref": "main",
  "commit": "abc123",
  "summary": "12 tests passed, 2 failed",
  "failures": [
    {"name": "test_login", "message": "Expected 200, got 401"}
  ],
  "url": "https://github.com/org/repo/actions/runs/123",
  "duration_ms": 45000
}
```

Response: `{"ok": true}` on success, appropriate error on failure.

The webhook has no authentication (localhost-only tool). Request body is limited to 1MB via `http.MaxBytesReader`. The endpoint stores the CI result and generates an alert.

Only the most recent 10 CI results are kept. Older results are evicted.

### Alert Generation Timing

- **Performance regressions**: Generated synchronously when `AddPerformanceSnapshot` is called on Capture (the existing baseline comparison runs at ingest time).
- **Anomaly detection**: Checked every time a new log entry is added. Uses a simple sliding window counter — no background goroutine needed.
- **CI results**: Generated synchronously on webhook receipt.
- **Threshold breaches**: Generated when memory/circuit state transitions occur (already detected in existing code).
- **Noise detection**: Generated when `auto_detect` noise action runs.

### Concurrency

The alert buffer has its own mutex (`alertMu sync.Mutex`) on `ToolHandler`. Alert generation acquires `alertMu` to append. Alert drain (in `observe` dispatch) acquires `alertMu` to read and clear. This is separate from `server.mu` and `capture.mu` to avoid lock ordering issues.

## Edge Cases

- If the alert buffer is full (50 entries) and a new alert arrives, the oldest alert is evicted. An additional meta-alert is NOT generated (to avoid infinite loops).
- If no `observe` call has ever been made, alerts still accumulate (up to the 50-entry cap).
- The CI webhook is idempotent — posting the same commit+status twice updates rather than duplicates.
- Empty `failures` array in CI webhook is valid (success case).
- Correlation window (5 seconds) uses the alert timestamps, not wall clock at drain time.

## Performance Constraints

- Alert generation must be O(1) — just append to a slice.
- Alert drain is O(n) where n ≤ 50 — copy and clear under mutex.
- CI webhook response must be under 5ms.
- Anomaly detection (error frequency check) is O(1) — maintains a counter, not a scan.

## Test Scenarios

1. Fresh server, no alerts: `observe` response has single content block (no alerts section).
2. Add performance regression: next `observe` call includes regression alert.
3. Multiple alerts accumulate: all are returned on next `observe`, then buffer is empty.
4. Alert cap (50): oldest evicted when buffer full.
5. CI webhook: POST valid result → alert generated → next `observe` includes CI alert.
6. CI webhook: POST invalid body → 400 error, no alert.
7. CI webhook: POST same commit twice → updates existing, no duplicate alert.
8. Situation synthesis: error + regression in same window → correlated compound alert.
9. Alert priority ordering: errors before warnings before info.
10. Deduplication: same regression repeated → single alert with count.
11. Summary prefix: 4+ alerts → starts with summary line.
12. Anomaly detection: error spike (>3x average) → anomaly alert generated.
13. Threshold breach: memory pressure transition → alert generated.
14. Noise auto-detect: new patterns found → info alert generated.

---

## Active Mode: Context Streaming

### Overview

Active mode pushes alerts as MCP notifications to stdout without requiring tool calls. This enables real-time awareness:

- "I notice you just got a 403 on /api/dashboard — let me check the auth middleware"
- "The page loaded 4 seconds slower than last time — looks like the new analytics script is blocking"

### MCP Tool: `configure_streaming`

```json
{
  "name": "configure_streaming",
  "description": "Configure proactive browser event notifications. When enabled, significant events are pushed as MCP notifications without explicit tool calls.",
  "inputSchema": {
    "type": "object",
    "properties": {
      "action": {
        "type": "string",
        "enum": ["enable", "disable", "status"],
        "description": "Enable/disable streaming or get current configuration"
      },
      "events": {
        "type": "array",
        "items": {
          "type": "string",
          "enum": ["errors", "network_errors", "performance", "user_frustration", "security", "regression", "anomaly", "ci", "all"]
        },
        "description": "Event categories to stream (default: all)"
      },
      "throttle_seconds": {
        "type": "integer",
        "minimum": 1,
        "maximum": 60,
        "description": "Minimum seconds between notifications (default: 5)"
      },
      "url_filter": {
        "type": "string",
        "description": "Only stream events for URLs containing this substring"
      },
      "severity_min": {
        "type": "string",
        "enum": ["info", "warning", "error"],
        "description": "Minimum severity to stream (default: warning)"
      }
    },
    "required": ["action"]
  }
}
```

### Disable Behavior (Off Switch)

`configure_streaming {action: "disable"}` immediately:
1. Sets `StreamConfig.Enabled = false`
2. Clears pending alert buffer
3. Stops all MCP notification emission
4. Returns confirmation: `{"status": "disabled", "pending_cleared": 3}`

This ensures the AI can stop noisy notifications instantly.

### MCP Notification Format

Uses standard MCP `notifications/message` method (not custom):

```json
{
  "jsonrpc": "2.0",
  "method": "notifications/message",
  "params": {
    "level": "warning",
    "logger": "gasoline",
    "data": {
      "category": "network_errors",
      "severity": "error",
      "title": "Server error: POST /api/users → 500",
      "detail": "Request failed with Internal Server Error",
      "timestamp": "2025-01-25T14:30:00.000Z",
      "context": {
        "method": "POST",
        "url": "/api/users",
        "status": 500,
        "duration_ms": 234
      },
      "correlation_id": "evt_abc123",
      "dedup_key": "POST:/api/users:500"
    }
  }
}
```

### Security: Context Redaction

**Critical:** Notification context is redacted using the same rules as tool responses:

- Headers in `SENSITIVE_HEADERS` list → `[REDACTED]`
- Request/response bodies → truncated, sensitive patterns masked
- URLs → query params with sensitive keys masked

```go
func (s *StreamState) emitNotification(event StreamEvent) {
    // Apply redaction before emission
    event.Context = s.redactionEngine.RedactMap(event.Context)

    notification := MCPNotification{
        JSONRPC: "2.0",
        Method:  "notifications/message",
        Params:  notificationParams{Level: event.Severity, Logger: "gasoline", Data: event},
    }

    // Write to stdout (MCP channel)
    json.NewEncoder(os.Stdout).Encode(notification)
}
```

### Throttling & Rate Limiting

| Parameter | Default | Range | Purpose |
|-----------|---------|-------|---------|
| `throttle_seconds` | 5 | 1-60 | Min gap between notifications |
| Max per minute | 12 | Fixed | Prevent flooding AI context |
| Dedup window | 30s | Fixed | Same message not repeated |
| Batch window | 2s | Fixed | Group rapid events |

### Implementation

```go
type StreamConfig struct {
    Enabled         bool     `json:"enabled"`
    Events          []string `json:"events"`
    ThrottleSeconds int      `json:"throttle_seconds"`
    URLFilter       string   `json:"url_filter"`
    SeverityMin     string   `json:"severity_min"`
}

type StreamState struct {
    Config         StreamConfig
    LastNotified   time.Time
    SeenMessages   map[string]time.Time // Dedup: message → last sent
    NotifyCount    int                  // Count in current minute
    MinuteStart    time.Time
    PendingBatch   []Alert
    mu             sync.Mutex
}

// On ToolHandler
type ToolHandler struct {
    // ... existing fields ...

    // Alert buffer (passive mode - attached to observe)
    AlertBuffer

    // Stream state (active mode - MCP notifications)
    streamState *StreamState
}
```

### Active Mode Test Scenarios

15. Enable streaming: `configure_streaming {action: "enable"}` → notifications start
16. Disable streaming: `configure_streaming {action: "disable"}` → notifications stop immediately
17. Status check: `configure_streaming {action: "status"}` → returns config + stats
18. Category filter: `events: ["errors"]` → only error notifications
19. URL filter: `url_filter: "/api/"` → only /api/ URLs
20. Severity filter: `severity_min: "error"` → only errors, not warnings
21. Throttling: 3 errors in 1 second → only first emitted, others batched
22. Rate limit: 15 events in 1 minute → only first 12 emitted
23. Dedup: same error 5 times → only first emitted within 30s window
24. Redaction: notification with auth header → header redacted in context

---

## Deferred to v2

- **Dedicated event endpoint (`/events/stream`):** For non-MCP consumers (dashboards, custom tooling)
- **WebSocket delivery:** Alternative push channel for bidirectional communication
- **Persistence:** Alerts lost on server restart; could persist to disk for recovery
