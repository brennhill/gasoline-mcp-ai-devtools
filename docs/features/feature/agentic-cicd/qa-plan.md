---
status: shipped
scope: feature/agentic-cicd/qa
ai-priority: medium
tags: [testing, qa]
relates-to: [product-spec.md, tech-spec.md]
last-verified: 2026-01-31
---

# QA Plan: Agentic CI/CD

> QA plan for the Agentic CI/CD feature. Covers data leak analysis, LLM clarity, simplicity assessment, code-level testing, and step-by-step UAT verification.

---

## 1. Data Leak Analysis

**Goal:** Verify the feature does NOT expose data it shouldn't. Gasoline runs on localhost and data must never leave the machine. Agentic CI/CD orchestrates self-healing tests, E2E repair, PR preview exploration, and deployment watchdog -- all of which touch CI pipelines, deployment APIs, and potentially production credentials.

| # | Data Leak Risk | What to Check | Severity |
|---|---------------|---------------|----------|
| DL-1 | CI environment variables exposed in MCP responses | Verify that `observe({what: "errors"})` and `/snapshot` responses do not include CI env vars (GITHUB_TOKEN, CI_DEPLOY_KEY, AWS_SECRET_ACCESS_KEY) that may appear in process.env or console output during CI runs | critical |
| DL-2 | Deployment API credentials in agent context | Verify that credentials used for rollback/deploy APIs are never returned in MCP tool responses, audit trail entries, or session snapshots | critical |
| DL-3 | Pre-commit hook bypass allowing credential commit | Verify that the self-healing test workflow does not commit files containing credentials (API keys, tokens, secrets) even when autonomously fixing tests | critical |
| DL-4 | Auth headers in network captures during CI | Verify that Authorization, Cookie, Set-Cookie, X-Auth-Token, X-API-Key, X-CSRF-Token, and Proxy-Authorization headers are stripped from network captures in CI mode identical to extension mode | critical |
| DL-5 | Network response bodies containing secrets | Verify that captured API response bodies do not leak tokens, session IDs, or API keys when the agent uses `observe({what: "network"})` to diagnose failures | high |
| DL-6 | Git diff data exposing secrets in fix commits | Verify that when the agent runs `analyze({target: "changes"})`, the response does not include file contents that contain credentials (e.g., .env files, config files with keys) | high |
| DL-7 | Webhook payloads containing repository secrets | Verify that webhook handlers receiving CI failure notifications do not forward repository secrets, deploy keys, or tokens to the Gasoline server | high |
| DL-8 | Snapshot data persisted to disk contains secrets | Verify that session snapshots saved via `configure({action: "store"})` apply redaction before writing to `.gasoline/` directory | medium |
| DL-9 | Audit trail entries expose sensitive diagnosis data | Verify that audit trail records of AI-generated commits and fix attempts do not include sensitive file contents or credentials | medium |
| DL-10 | PR preview URLs containing auth tokens in query strings | Verify that preview URLs with embedded tokens (e.g., `?token=abc123`) are redacted in MCP responses and reports | medium |

### Negative Tests (must NOT leak)
- [ ] CI env vars (GITHUB_TOKEN, CI_JOB_TOKEN, AWS_SECRET_ACCESS_KEY) must not appear in any MCP tool response
- [ ] Deployment API credentials must not appear in audit trail or session data
- [ ] Response bodies with tokens must have tokens redacted in `observe` output
- [ ] `.env` file contents must not appear in `analyze({target: "changes"})` output
- [ ] Webhook handler must not forward GitHub webhook secrets to Gasoline
- [ ] Git commit messages generated by AI must not contain credential values
- [ ] Pre-existing auth cookies must not appear in snapshot baseline data

---

## 2. LLM Clarity Assessment

**Goal:** Verify an AI agent reading the tool responses can unambiguously understand the data without misinterpretation.

| # | Clarity Check | What to Verify | Status |
|---|--------------|----------------|--------|
| CL-1 | Distinguish build failure from test failure | Verify that error responses clearly differentiate "build failed" (compilation/bundling error) from "test failed" (assertion failure) so the AI does not attempt to fix test assertions when the build is broken | [ ] |
| CL-2 | Root cause vs symptom in error output | Verify that `observe({what: "errors"})` presents errors in a way that distinguishes root cause errors from cascading failures (e.g., one missing import causes 10 test failures) | [ ] |
| CL-3 | Flaky test vs true regression signal | Verify that test failure data includes pass/fail history or flake rate so the AI can distinguish a flaky test (>10% flake rate) from a genuine regression | [ ] |
| CL-4 | Selector change vs component removal | Verify that DOM observation data clearly shows whether an element is absent (component removed) vs renamed (selector changed) so the AI makes the correct fix decision | [ ] |
| CL-5 | API contract change direction | Verify that network observation data shows both the expected and actual API response shape so the AI knows which direction the change went (e.g., camelCase to snake_case) | [ ] |
| CL-6 | Circuit breaker status clarity | Verify that when the circuit breaker activates (max 3 fix attempts), the response unambiguously states "circuit breaker activated -- manual intervention required" rather than a generic failure | [ ] |
| CL-7 | Verification loop result interpretation | Verify that `verify_fix({action: "compare"})` response clearly states pass/fail with specific metrics, not just a boolean, so the AI understands what regressed or improved | [ ] |
| CL-8 | Protected file handling message | Verify that when the AI attempts to modify a protected file, the error message clearly explains why the fix cannot be applied (permissions, .gitignore, etc.) | [ ] |
| CL-9 | Health check failure vs feature unavailability | Verify that when `GET /health` returns non-200, the error message distinguishes "server not running" from "server running but feature unavailable" | [ ] |
| CL-10 | Concurrent failure grouping | Verify that when multiple tests fail from the same root cause, the grouping is explicit (e.g., "5 tests failed from error signature X") so the AI does not attempt 5 separate fixes | [ ] |

### Common LLM Misinterpretation Risks
- [ ] AI might interpret "test timed out" as "test assertion failed" -- verify timeout errors are clearly labeled
- [ ] AI might fix a test selector when the underlying component was intentionally removed -- verify DOM diff shows removal vs rename
- [ ] AI might retry indefinitely without recognizing the circuit breaker limit -- verify circuit breaker messaging is unambiguous
- [ ] AI might confuse "pre-existing error in baseline" with "new regression" -- verify baseline errors are clearly excluded from regression reports
- [ ] AI might apply fixes to the wrong branch or commit -- verify git context (branch, SHA) is included in all diagnosis responses

---

## 3. Simplicity Assessment

**Goal:** Count steps and evaluate cognitive load for both human and AI users.

**Complexity Score:** High

| Workflow | Steps Required | Can Be Simplified? |
|----------|---------------|-------------------|
| Self-healing test (Feature 33) | 11 steps (receive notification, check health, re-run test, capture snapshot, observe errors/network/DOM, diagnose, start verify, fix, compare verify, commit) | No -- each step is necessary, but steps 5-6 (observe) could be combined into a single multi-mode observe call |
| Agentic E2E repair (Feature 34) | 8 steps (capture failure, observe network response, compare to expectation, diagnose, search codebase, propose fix, implement, verify) | Yes -- steps 2-4 could be a single `analyze({target: "api"})` call if API schema inference returns both actual and expected |
| PR preview exploration (Feature 35) | 8 steps (get preview URL, open tab, explore app, observe errors, capture state, diagnose findings, generate report, post PR comment) | No -- exploration is inherently multi-step, but URL discovery could have a zero-config default |
| Deployment watchdog (Feature 36) | 9 steps (pre-deploy baseline, deploy, post-deploy capture, compare sessions, detect regression, diagnose, decide severity, trigger rollback, notify) | Yes -- watchdog could auto-capture baseline and eliminate step 1 if auto-deploy detection is implemented |

### Default Behavior Verification
- [ ] Self-healing: Skill `preconditions` automatically check Gasoline health before attempting diagnosis
- [ ] Circuit breaker defaults to max 3 fix attempts without requiring explicit configuration
- [ ] Flaky test threshold defaults to 10% without requiring explicit configuration
- [ ] Verification loop runs automatically after fix without requiring explicit compare call
- [ ] Human approval gate is ON by default for security-related test changes
- [ ] Deployment watchdog pre-deploy baseline capture is required (no auto-detection) -- verify this is documented as a prerequisite

---

## 4. Code Test Plan

### 4.1 Unit Tests

| # | Test Case | Input | Expected Output | Priority |
|---|-----------|-------|-----------------|----------|
| UT-1 | Skill precondition health check passes | `GET /health` returns 200 | Skill proceeds to workflow step 1 | must |
| UT-2 | Skill precondition health check fails | `GET /health` returns 503 or connection refused | Skill returns clear error: "Gasoline server not running" | must |
| UT-3 | Circuit breaker activates after 3 attempts | 3 consecutive fix attempts for same test | Fourth attempt is blocked, returns circuit breaker message | must |
| UT-4 | Flaky test detection at threshold | Test with 11% flake rate (>10%) | Test marked as "flaky", no fix attempted | must |
| UT-5 | Error signature grouping | 10 test failures with same error fingerprint | Grouped into 1 failure group, not 10 independent failures | must |
| UT-6 | Protected file detection | Fix attempt targets `.gitignore`-listed file | Fix blocked, returns "protected file" message | should |
| UT-7 | API contract diff detection | Network response `{user_name: "Alice"}` vs expected `{userName: "Alice"}` | Diff shows field name change from camelCase to snake_case | must |
| UT-8 | Selector change detection | DOM missing `.submit-btn` but has `.btn-submit` | Diagnosis: "Selector changed from .submit-btn to .btn-submit" | must |
| UT-9 | Cascading failure deduplication | 10 tests fail, all referencing `PaymentService is not defined` | Single root cause identified, fix applied once | should |
| UT-10 | Verify fix comparison with improvement | Before: 2 errors. After: 0 errors | Verification result: "pass", delta shows -2 errors | must |
| UT-11 | Verify fix comparison with no change | Before: 2 errors. After: 2 errors (same) | Verification result: "fail", delta shows 0 change | must |
| UT-12 | Verify fix comparison with regression | Before: 2 errors. After: 3 errors (new one) | Verification result: "fail", delta shows +1 error | must |

### 4.2 Integration Tests

| # | Test Case | Components Involved | Expected Behavior | Priority |
|---|-----------|--------------------|--------------------|----------|
| IT-1 | End-to-end self-healing workflow | Gasoline server + observe tool + verify_fix + snapshot endpoint | Agent receives test failure, captures state, diagnoses selector change, applies fix, verifies fix passes | must |
| IT-2 | CI webhook triggers skill execution | Webhook handler + Claude Code skill + Gasoline server | `ci/test-failure` webhook triggers self-heal skill, skill calls Gasoline tools in sequence | must |
| IT-3 | API contract drift detection | observe(network) + analyze(api) + verify_fix | Agent detects `userName` -> `user_name` change across network response, proposes and verifies fix | must |
| IT-4 | Audit trail records all AI commits | Self-healing fix + git commit + audit_trail | Every AI-generated commit is recorded in `configure({action: "audit_log"})` with commit SHA, diagnosis, and fix description | should |
| IT-5 | Pre-commit hook blocks credential commit | Self-healing fix + pre-commit hook | Fix that accidentally includes a credential is blocked by pre-commit hook, agent retries without credential | should |
| IT-6 | Multi-test failure with single root cause | 5 test failures + error grouping + single fix | Agent groups failures, applies one fix, all 5 tests pass on re-run | should |
| IT-7 | Human approval gate for security test changes | Security-related test fix + approval gate | Agent proposes fix but waits for human approval before committing | should |

### 4.3 Performance Tests

| # | Test Case | Metric | Target | Priority |
|---|-----------|--------|--------|----------|
| PT-1 | Snapshot capture time in CI | Time to capture full browser state via `/snapshot` | < 200ms for 1000 log entries + 100 network bodies | must |
| PT-2 | Error grouping for large failure sets | Time to group 50 test failures by error fingerprint | < 100ms | should |
| PT-3 | Verify fix comparison speed | Time for `verify_fix({action: "compare"})` | < 50ms per comparison | must |
| PT-4 | Concurrent skill execution | Memory usage with 3 parallel skill instances | < 150MB total server memory | should |
| PT-5 | CI endpoint response under load | `/snapshot` response time with concurrent requests from 10 workers | < 500ms p99 | should |

### 4.4 Edge Case Tests

| # | Edge Case | Input/Scenario | Expected Behavior | Priority |
|---|-----------|---------------|-------------------|----------|
| EC-1 | True regression (feature intentionally removed) | Test fails because component was removed by design | Agent detects code change, flags for human review rather than auto-fixing | must |
| EC-2 | Infinite fix loop (fix causes new failure) | Fix #1 passes test A but breaks test B | Circuit breaker activates after 3 total attempts, stops and reports | must |
| EC-3 | Test passes on retry (transient flake) | Test fails once, passes on immediate retry | Agent records flake occurrence, does not generate a fix commit | must |
| EC-4 | Gasoline server restarts during workflow | Server restarts after baseline capture but before comparison | Agent detects server unavailability, re-captures baseline, retries workflow | should |
| EC-5 | No browser tab available | CI environment has no headed browser | Agent uses headless capture via gasoline-ci.js, not extension | must |
| EC-6 | Empty test output (no errors, no network) | Test fails with assertion error only, no console errors or network failures | Agent diagnoses from assertion message alone, reports limited observability | should |
| EC-7 | Very large codebase search (1000+ files) | Agent searches for all references to changed API field | Search completes in reasonable time, does not exceed context window | should |
| EC-8 | Protected branch prevents push | Agent attempts to push fix to protected branch | Agent creates fix on a new branch instead, or reports that it cannot push directly | should |

---

## 5. UAT Checklist (Human + AI)

> Step-by-step verification for a human working with an AI assistant. The AI executes MCP tool calls; the human observes browser behavior and confirms results.

### Prerequisites
- [ ] Gasoline server running: `./dist/gasoline --port 7890`
- [ ] Chrome extension installed and connected
- [ ] A test project with at least one Playwright or Cypress test that can be intentionally broken
- [ ] Git repository initialized in the test project
- [ ] Claude Code or MCP client available

### Step-by-Step Verification

| # | Step (AI executes) | Human Observes | Expected Result | Pass |
|---|-------------------|----------------|-----------------|------|
| UAT-1 | AI checks Gasoline health: `GET http://127.0.0.1:7890/health` | Server responds in terminal | HTTP 200 returned, AI confirms server is running | [ ] |
| UAT-2 | AI captures baseline: `{"tool":"observe","arguments":{"what":"errors"}}` | No errors in clean state | Empty error list returned | [ ] |
| UAT-3 | Human intentionally breaks a test (change a CSS selector in app code) | Test now fails when run | Test failure confirmed | [ ] |
| UAT-4 | AI re-runs failing test with Gasoline capture | Test output shows failure | AI receives test failure notification | [ ] |
| UAT-5 | AI captures failure state: `{"tool":"observe","arguments":{"what":"errors"}}` | Console errors visible in browser DevTools | AI receives error list including the selector-not-found error | [ ] |
| UAT-6 | AI observes DOM: `{"tool":"interact","arguments":{"action":"execute_js","script":"document.querySelector('.btn-submit')"}}` | Element found with new selector | AI identifies the new selector name | [ ] |
| UAT-7 | AI starts verification: `{"tool":"configure","arguments":{"action":"verify_fix","verify_action":"start"}}` | Verification session started | Baseline captured for comparison | [ ] |
| UAT-8 | AI applies fix (updates selector in test file) | Git diff shows selector change | Test file modified with correct new selector | [ ] |
| UAT-9 | AI re-runs test to verify fix | Test output shows pass | Test passes with new selector | [ ] |
| UAT-10 | AI completes verification: `{"tool":"configure","arguments":{"action":"verify_fix","verify_action":"compare"}}` | Comparison results shown | Verification shows pass (errors resolved) | [ ] |
| UAT-11 | AI commits fix with explanation | Git log shows new commit | Commit message explains the selector change and includes AI attribution | [ ] |
| UAT-12 | Verify audit trail: `{"tool":"configure","arguments":{"action":"audit_log"}}` | Audit log entry visible | Entry shows tool calls made during diagnosis and fix | [ ] |

### Data Leak UAT Verification

| # | Check | Method | Expected | Pass |
|---|-------|--------|----------|------|
| DL-UAT-1 | No env vars in observe output | Set `SECRET_KEY=abc123` env var, run `observe({what: "errors"})` | SECRET_KEY value does not appear in response | [ ] |
| DL-UAT-2 | Auth headers stripped from network capture | Make authenticated API call, run `observe({what: "network"})` | Authorization header value shows `[REDACTED]` | [ ] |
| DL-UAT-3 | Snapshot does not contain credentials | Run `/snapshot`, search response for any known credentials | No credential values found in snapshot JSON | [ ] |
| DL-UAT-4 | AI commit does not contain secrets | Review AI-generated commit diff | No API keys, tokens, or passwords in committed code | [ ] |
| DL-UAT-5 | Audit trail is credential-free | Query audit log for all entries | No credential values in any audit trail entry | [ ] |

### Regression Checks
- [ ] Existing `observe` functionality still works after agentic CI/CD features are enabled
- [ ] Existing `verify_fix` functionality works independently of the CI/CD workflow
- [ ] Extension capture is not affected by CI capture script when both are present
- [ ] MCP tool responses maintain the same schema as before the feature
- [ ] Performance of existing tools is not degraded by new workflow overhead

---

## Sign-Off

| Area | Tester | Date | Pass/Fail |
|------|--------|------|-----------|
| Data Leak Analysis | | | |
| LLM Clarity | | | |
| Simplicity | | | |
| Code Tests | | | |
| UAT | | | |
| **Overall** | | | |
